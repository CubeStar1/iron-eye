PROBLEMS 
IR CLASSIFICATION IS A USEFUL TOOL FOR QUICKLY ANALYSING 
THERMAL FOOTAGE, BUT THERE ARE SOME DRAWBACKS 
COMPARED TO CLASSIFICATION OF RGB IMAGES
 ● IR IMAGERY OFTEN HAS LOWER RESOLUTION
 ● THE CONTRAST BETWEEN OBJECTS IN IR IMAGERY IS 
OFTEN LOW DUE TO THE NORMALIZED COLOUR SCALE 
● OBJECTS CHANGE VISUALLY DUE TO SHEDDING/GAINING 
HEAT OVER TIME, 
● WEATHER CAN IMPACT IR, REDUCING OR INCREASING 
THE HEAT OF METAL SURFACES FOR EXAMPL


SOLUTION
 EO/IR CAMERAS OUTPUT 2 VIDEO FEEDS, ONE IN RGB AND ONE IN IR, BOTH CAPTURE DIFFERENT 
FEATURES THAT THE OTHER ONE MAY NOT.
 WE CAN TAKE ADVANTAGE OF THIS BY COMBINING FEATURES OF BOTH 
PRE EXISTING METHODS
 A WAY OF DOING THIS IS WITH “FUSION” WHICH EXTRACTS FEATURES FROM BOTH RGB AND IR AND 
MERGES THEM INSIDE THE DEEPER LAYERS OF THE ML MODEL, HOWEVER THIS REQUIRES 2 
DIFFERENT INPUTS AND INCREASES COMPLEXITY, MAKING CLASSIFICATION TAKE LONGER 
PROPOSED METHOD
 OUR SOLUTION IS A MUCH MORE LIGHTWEIGHT MERGE, WHERE EDGE DETAILS FROM THE RGB 
IMAGE ARE EXTRACTED AND OVERLAID ONTO THE IR IMAGE BEFORE CLASSIFICATION, PROVIDING 
THE CONTRAST OF RGB IMAGES THAT IR LACKS, THIS MEANS THAT A SINGLE INPUT IS REQUIRED AND 
THE COMPLEXITY IS LOWERED
 THIS ALLOWS THE CLASSIFICATION MODEL TO BE POTENTIALLY DEPLOYED ON EDGE AI 
APPLICATIONS REMOTELY, SUCH AS DRONE


METHODOLOGY
 1. REAL-TIME DATA INGESTION: ESTABLISH A DUAL STREAM REAL-TIME RGB AND IR VIDEO FEED 
FROM THE EO/IR CAMERA SYSTEM, ENSURING SYNCHRONIZED CAPTURE FOR BOTH 
MODALITIES.
 2. RGB EDGE DETECTION: APPLY EDGE DETECTION TECHNIQUES (E.G., CANNY EDGE DETECTION, 
SOBEL FILTER PROCESSING, GRADIENT CALCULATION, NOISE REDUCTION) SPECIFICALLY TO 
THE RGB VIDEO STREAM TO HIGHLIGHT OBJECT BOUNDARIES.
 3. LIGHTWEIGHT FUSION: PERFORM AN OPTIMIZED, LIGHTWEIGHT FUSION OF THE RGB EDGE 
INFORMATION ONTO THE IR VIDEO STREAM. THIS STEP SHOULD INCLUDE RGB EDGE OVERLAY 
ON IR, CONTRAST ENHANCEMENT, SINGLE INPUT GENERATION, AND BE SPECIFICALLY 
OPTIMIZED FOR EDGE AI DEPLOYMENT.
 4. OBJECT CLASSIFICATION: EXECUTE YOLOV8 INFERENCE ON THE FUSED STREAM TO IDENTIFY 
AND CLASSIFY OBJECTS. THIS INVOLVES MULTI-CLASS DETECTION, CONFIDENCE SCORING, 
AND BOUNDING BOX GENERATION.
 5. OUTPUT CLASSIFICATION: GENERATE DETAILED DETECTION RESULTS INCLUDING STATIC 
OBJECTS, MOVING OBJECTS, THERMAL SIGNATURES, HIDDEN OBJECTS, AND ENVIRONMENTAL 
FEATURES BASED ON THE YOLOV8 OUTPUT.
 6. BACKEND STREAM PROCESSING & EDGE DETECTION: THE PROCESSED VIDEO STREAMS AND 
EDGE DETECTION RESULTS ARE FED INTO THE BACKEND'S STREAM PROCESSING MODULE. 
THIS MODULE HANDLES DUAL VIDEO STREAM PROCESSING, REAL-TIME WEBSOCKET 
COMMUNICATION, AND PRE-PROCESSING FOR EDGE DETECTION.
 7. DATABASE INTEGRATION: STORE REAL-TIME DETECTION METADATA, VIDEO STREAM ARCHIVAL, 
OBJECT TRACKING HISTORY, PERFORMANCE METRICS, CLASSIFICATION CONFIDENCE SCORES
 8. LIVE DASHBOARD DEVELOPMENT: DEVELOP A COMPREHENSIVE LIVE DASHBOARD USING 
REACT, TYPESCRIPT, AND TAILWIND CSS. THIS DASHBOARD WILL FEATURE DUAL VIDEO STREAM 
DISPLAY WITH SYNC, REAL-TIME OBJECT DETECTION OVERLAY, EDGE DETECTION 
VISUALIZATION, CLASSIFICATION RESULTS DASHBOARD, AND AN AI ASSISTANT FOR 
SUMMARIZATION.
 9. MONITORING AND OPTIMIZATION: CONTINUOUSLY MONITOR SYSTEM PERFORMANCE, 
INCLUDING INFERENCE SPEED, DATA THROUGHPUT, AND ACCURACY, MAKING ITERATIVE 
OPTIMIZATIONS TO THE ML MODELS AND SYSTEM ARCHITECTURE